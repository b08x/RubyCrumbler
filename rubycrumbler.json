{
  "files": [
    {
      "filename": "crumbler.rb",
      "path": "/",
      "content": "#!/usr/bin/env ruby\n\nrequire 'open-uri'\nrequire 'nokogiri'\nrequire 'fileutils'\nrequire 'ruby-spacy'\nrequire 'glimmer-dsl-libui'\nrequire 'csv'\nrequire 'builder'\nrequire 'tk'\nrequire 'terminal-table'\nrequire 'ruby-progressbar'\nrequire 'pragmatic_tokenizer'\n\n# Load configuration\nrequire_relative '../config/settings'\n\n# Load core functionality\nrequire_relative 'utils/logging'\n\nrequire_relative 'crumbler/pipeline/features'\nrequire_relative 'crumbler/gui/crumbler_gui'\n\nmodule Crumbler\n  include Logging\n  class Error < StandardError; end\n\n  class << self\n    def root\n      File.expand_path('..', __dir__)\n    end\n\n    def env\n      ENV['CRUMBLER_ENV'] || 'development'\n    end\n\n    def development?\n      env == 'development'\n    end\n\n    def test?\n      env == 'test'\n    end\n\n    def production?\n      env == 'production'\n    end\n\n    def version\n      Config::APP_VERSION\n    end\n\n    def configure\n      yield(configuration) if block_given?\n    end\n\n    def configuration\n      @configuration ||= Configuration.new\n    end\n  end\n\n  # Configuration class for custom settings\n  class Configuration\n    attr_accessor :custom_language_models,\n                  :output_directory,\n                  :max_file_size\n\n    def initialize\n      @custom_language_models = {}\n      @output_directory = File.join(Dir.pwd, 'output')\n      @max_file_size = Config::MAX_FILE_SIZE\n    end\n  end\n\n  # Initialize default configuration\n  configure do |config|\n    # Add any custom configuration here\n  end\nend\n"
    },
    {
      "filename": "crumbler_gui.rb",
      "path": "/crumbler/gui/",
      "content": "#!/usr/bin/env ruby\n\nrequire_relative 'components/menu_bar'\nrequire_relative 'components/input_section'\nrequire_relative 'components/processing_options'\nrequire_relative 'components/run_section'\n\nmodule Crumbler\n  module GUI\n    class CrumblerGUI\n      include Logging\n      include Glimmer\n      include Crumbler::Pipeline\n\n      def initialize\n        ProgressBar.create\n        @menu_bar = Components::MenuBar.new\n        @input_section = Components::InputSection.new\n      end\n\n      def launch\n        @menu_bar.create\n        create_main_window\n      end\n\n      private\n\n      def create_main_window\n        window('Crumbler', 300, 800) do\n          margined(true)\n          vertical_box do\n            @input_section.create\n            horizontal_separator { stretchy false }\n            create_run_section\n          end\n        end.show\n      end\n\n      def create_run_section\n        @run_section = Components::RunSection.new(@input_section, @input_section.processing_options)\n        @run_section.create\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "menu_bar.rb",
      "path": "/crumbler/gui/components/",
      "content": "#!/usr/bin/env ruby\n\nmodule Crumbler\n  module GUI\n    module Components\n      class MenuBar\n        include Glimmer\n\n        def create\n          menu('Help') do\n            create_about_menu_item\n            create_documentation_menu_item\n          end\n        end\n\n        private\n\n        def create_about_menu_item\n          menu_item('About') do\n            on_clicked do\n              window('About Crumbler', 700, 500, false) do\n                on_closing do\n                  window.destroy\n                  1\n                end\n                margined true\n                vertical_box do\n                  area do\n                    text do\n                      default_font family: 'Helvetica', size: 13, weight: :normal, italic: :normal, stretch: :normal\n                      string do\n                        font family: 'Helvetica', size: 14, weight: :bold, italic: :normal, stretch: :normal\n                        \"Crumbler Version #{Crumbler::VERSION}\\n\\n\"\n                      end\n                      string(\"Developed by Laura Bernardy, Nora Dirlam, Jakob Engel, and Johanna Garthe.\\nMarch 31, 2022\\n\\nThis project is open source on GitHub.\")\n                    end\n                  end\n                  button('Go to GitHub Repository') do\n                    stretchy true\n                    on_clicked do\n                      system('open', 'https://github.com/joh-ga/Crumbler')\n                    end\n                  end\n                end\n              end.show\n            end\n          end\n        end\n\n        def create_documentation_menu_item\n          menu_item('Documentation') do\n            on_clicked do\n              window('Documentation', 400, 600, false) do\n                on_closing do\n                  window.destroy\n                  1\n                end\n                margined true\n                vertical_box do\n                  area do\n                    text do\n                      default_font family: 'Helvetica', size: 12, weight: :normal, italic: :normal, stretch: :normal\n                      string do\n                        font family: 'Helvetica', size: 13, weight: :bold, italic: :normal, stretch: :normal\n                        \"Description of Features\\n\\n\"\n                      end\n                      string(\"Please find below all the necessary information about the individual features.\\n\\n\")\n                      create_documentation_text\n                    end\n                  end\n                  button('Go to GitHub Repository') do\n                    stretchy false\n                    on_clicked do\n                      system('open', 'https://github.com/joh-ga/Crumbler')\n                    end\n                  end\n                end\n              end.show\n            end\n          end\n        end\n\n        def create_documentation_text\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            underline :single\n            \"Pre-Processing\\n\"\n          end\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Data cleaning: '\n          end\n          string(\"This includes removing redundant whitespaces, punctuation (redundant dots), special symbols (e.g., line break, new line), hash tags, HTML tags, and URLs.\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Normalization: '\n          end\n          string(\"This includes removing punctuation symbols (dot, colon, comma, semicolon, exclamation and question mark).\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Normalization (lowercase): '\n          end\n          string(\"This includes removing punctuation symbols (dot, colon, comma, semicolon, exclamation and question mark) as well as converting the text into lowercase.\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Normalization (contractions): '\n          end\n          string(\"This includes removing punctuation symbols (dot, colon, comma, semicolon, exclamation and question mark) as well as converting contractions)\\n\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            underline :single\n            \"Natural Language Processings â€“ Tasks \\n\"\n          end\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Tokenization: '\n          end\n          string(\"This includes splitting the pre-processed data into individual characters or tokens.\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Stopword removal: '\n          end\n          string(\"Stopwords are words that do not carry much meaning but are important grammatically as\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Lemmatization: '\n          end\n          string(\"This includes reduction of a word to its semantic base form according to POS classification. Examples: computing - compute, sung - sing, obviously - obviously.\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Part-of-Speech Tagging: '\n          end\n          string(\"This includes identifying and labeling the parts of speech of text data.\\n\")\n          string do\n            font family: 'Helvetica', size: 12, weight: :bold, italic: :normal, stretch: :normal\n            'Named Entity Recognition: '\n          end\n          string(\"This includes labeling the so-called named entities\\n\\n\\n\")\n          string do\n            font family: 'Helvetica', size: 13, weight: :bold, italic: :normal, stretch: :normal\n            \"Information about the File Naming Convention\\n\\n\"\n          end\n          string(\"To enable a quick identification and location of your converted document depending on the feature applied, the following file naming convention is used in Crumbler.\\n\\n\\n\")\n          string do\n            font family: 'Helvetica', size: 13, weight: :bold, italic: :normal, stretch: :normal\n            \"Notes\\n\\n\"\n          end\n          string('More information and the source code are available on GitHub.')\n        end\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "input_section.rb",
      "path": "/crumbler/gui/components/",
      "content": "#!/usr/bin/env ruby\n\nmodule Crumbler\n  module GUI\n    module Components\n      class InputSection\n        include Glimmer\n\n        attr_reader :lang, :input, :projectname, :doc, :processing_options\n\n        def initialize\n          @lang = 'EN'\n          @processing_options = Components::ProcessingOptions.new\n        end\n\n        def create\n          horizontal_box do\n            stretchy false\n            vertical_box do\n              create_language_selection\n              create_upload_center\n            end\n            create_processing_options_box\n          end\n        end\n\n        private\n\n        def create_language_selection\n          group('Language of Text Input') do\n            stretchy false\n            vertical_box do\n              label(\"Please specify the language in which your input text data is written.\\n\" \\\n              \"Note: This information is mandatory to run the program.\\n\") { stretchy false }\n\n              combobox do\n                stretchy false\n                items 'English', 'German'\n                selected 'English'\n\n                on_selected do |c|\n                  @lang = if c.selected_item == 'English'\n                            'EN'\n                          else\n                            'DE'\n                          end\n                end\n              end\n              label\n            end\n          end\n        end\n\n        def create_upload_center\n          group('Upload Center') do\n            stretchy false\n            vertical_box do\n              label(\"Choose a file(s) or a directory, or specify a URL whose text content should be used to upload.\\n\" \\\n              \"Note: Total file size may not exceed 50MB. File type must be TXT.\\n\") do\n                stretchy false\n              end\n              create_file_upload_button\n              create_directory_upload_button\n              create_url_upload_section\n            end\n          end\n        end\n\n        def create_file_upload_button\n          button('Upload from file(s)') do\n            stretchy false\n            on_clicked do\n              file = open_file\n              if file.nil?\n                msg_box('ERROR: No File selected.')\n              else\n                @input = file\n                @projectname = File.basename(@input, '.*')\n                @doc = Crumbler::Pipeline::Features.new\n                puts @input unless file.nil?\n                @doc.newproject(@input, @projectname)\n                msg_box('Notification', 'Upload successfully completed.')\n              end\n            end\n          end\n        end\n\n        def create_directory_upload_button\n          button('Upload file(s) from directory') do\n            stretchy false\n            on_clicked do\n              dir = Tk.chooseDirectory\n              @input = dir\n              @projectname = File.basename(@input, '.*')\n              @projectname = \"#{@projectname}_process\"\n              if @projectname == '_process'\n                msg_box('ERROR: No Folder selected.')\n              else\n                @doc = Crumbler::Pipeline::Features.new\n                @doc.newproject(@input, @projectname)\n                msg_box('Notification', 'Upload successfully completed.')\n              end\n            end\n          end\n        end\n\n        def create_url_upload_section\n          label(\"\\nEnter URL:\") { stretchy false }\n          @entry = entry do\n            stretchy false\n            on_changed do\n              @url = @entry.text\n            end\n          end\n          button('Upload text from website') do\n            stretchy false\n            on_clicked do\n              @input = @url\n              if @input.nil?\n                msg_box('ERROR: No URL selected.')\n              else\n                @projectname = File.basename(@input, '.*')\n                @doc = Crumbler::Pipeline::Features.new\n                puts @input unless @input.nil?\n                @doc.newproject(@input, @projectname)\n                msg_box('Notification', 'Upload successfully completed.')\n              end\n            end\n          end\n        end\n\n        def create_processing_options_box\n          vertical_box do\n            @processing_options.create(self)\n          end\n        end\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "processing_options.rb",
      "path": "/crumbler/gui/components/",
      "content": "#!/usr/bin/env ruby\n\nmodule Crumbler\n  module GUI\n    module Components\n      class ProcessingOptions\n        include Glimmer\n\n        attr_accessor :count, :clcbchecked, :normchecked, :normlowchecked, :normcontchecked,\n                      :tokchecked, :srchecked, :lemchecked, :poschecked, :nerchecked,\n                      :autotokchecked, :norm, :tok\n\n        def initialize\n          @count = 0\n          @clcbchecked = false\n          @normchecked = false\n          @normlowchecked = false\n          @normcontchecked = false\n          @tokchecked = false\n          @srchecked = false\n          @lemchecked = false\n          @poschecked = false\n          @nerchecked = false\n          @autotokchecked = false\n        end\n\n        def create(container)\n          container.vertical_box do\n            create_preprocessing_group\n            create_nlp_group\n          end\n        end\n\n        private\n\n        def create_preprocessing_group\n          group('Pre-Processing') do\n            stretchy false\n            vertical_box do\n              label(\"Select all or respective features.\\n\" \\\n              'Note: See the documentation for more information about each feature.') { stretchy false }\n\n              @clcb = checkbox('Data cleaning') do\n                stretchy false\n                on_toggled do |_c|\n                  @clcbchecked = @clcb.checked?\n                  self.count += 1 if @clcb.checked?\n                end\n              end\n\n              @norm = checkbox('Normalization') do\n                stretchy false\n                on_toggled do |_c|\n                  @normchecked = @norm.checked?\n                  self.count += 1 if @norm.checked?\n                end\n              end\n\n              @normlow = checkbox('Normalization (lowercase)') do\n                stretchy false\n                on_toggled do |_c|\n                  @normlowchecked = @normlow.checked?\n                  self.count += 1 if @normlow.checked?\n                end\n              end\n\n              @normcont = checkbox('Normalization (contractions)') do\n                stretchy false\n                on_toggled do |_c|\n                  @normcontchecked = @normcont.checked?\n                  self.count += 1 if @normcont.checked?\n                end\n              end\n            end\n          end\n        end\n\n        def create_nlp_group\n          group('Natural Language Processing â€“ Tasks') do\n            stretchy false\n            vertical_box do\n              label(\"Select all or respective features.\\n\" \\\n              'Note: See the documentation for more information about each feature.') { stretchy false }\n\n              @tok = checkbox('Tokenization') do\n                stretchy false\n                on_toggled do |_c|\n                  @tokchecked = @tok.checked?\n                  self.count += 1 if @tok.checked?\n                end\n              end\n\n              @sr = checkbox('Stopword removal') do\n                stretchy false\n                on_toggled do |_c|\n                  @srchecked = @sr.checked?\n                  self.count += 1 if @sr.checked?\n                end\n              end\n\n              @lem = checkbox('Lemmatization') do\n                stretchy false\n                on_toggled do |_c|\n                  @lemchecked = @lem.checked?\n                  self.count += 1 if @lem.checked?\n                end\n              end\n\n              @pos = checkbox('Part-of-Speech Tagging') do\n                stretchy false\n                on_toggled do |_c|\n                  @poschecked = @pos.checked?\n                  self.count += 1 if @pos.checked?\n                end\n              end\n\n              @ner = checkbox('Named Entity Recognition') do\n                stretchy false\n                on_toggled do |_c|\n                  @nerchecked = @ner.checked?\n                  self.count += 1 if @ner.checked?\n                end\n              end\n            end\n          end\n        end\n\n        def enable_tokenization\n          @autotokchecked = true\n          @tok.checked = true if @tok\n        end\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "run_section.rb",
      "path": "/crumbler/gui/components/",
      "content": "#!/usr/bin/env ruby\n\nmodule Crumbler\n  module GUI\n    module Components\n      class RunSection\n        include Glimmer\n        include Crumbler::Pipeline\n\n        attr_reader :fincount, :progressbar, :label\n\n        def initialize(input_section, processing_options)\n          @input_section = input_section\n          @processing_options = processing_options\n          @fincount = 0\n        end\n\n        def create\n          horizontal_box do\n            stretchy false\n            group do\n              vertical_box do\n                create_run_button\n                create_progress_section\n                create_new_project_button\n              end\n            end\n          end\n        end\n\n        private\n\n        def create_run_button\n          button('Run') do\n            stretchy false\n            on_clicked do\n              process_text\n            end\n          end\n        end\n\n        def create_progress_section\n          label { stretchy false }\n          @progressbar = progress_bar do\n            stretchy false\n          end\n          @label = label do\n            stretchy false\n          end\n        end\n\n        def create_new_project_button\n          button('New Project') do\n            stretchy false\n            on_clicked do\n              window.destroy\n              Kernel.exec('ruby rubycrumbler_maclinux.rb')\n            end\n          end\n        end\n\n        def process_text\n          process_preprocessing\n          process_nlp\n        end\n\n        def process_preprocessing\n          if @processing_options.clcbchecked\n            cleaner = Pipeline::Cleaner.new\n            clean_text = cleaner.process(File.read(@input_section.input))\n            update_progress\n          end\n\n          process_normalization\n        end\n\n        def process_normalization\n          if @processing_options.normchecked && !@processing_options.normlowchecked && !@processing_options.normcontchecked\n            @input_section.doc.normalize(false, @input_section.lang, false)\n            update_progress\n          elsif (@processing_options.normchecked && @processing_options.normlowchecked && !@processing_options.normcontchecked) ||\n                (@processing_options.normchecked && @processing_options.normcontchecked && !@processing_options.normlowchecked)\n            @input_section.doc.normalize(@processing_options.normcontchecked, @input_section.lang,\n                                         @processing_options.normlowchecked)\n            update_progress(2)\n          elsif @processing_options.normchecked && @processing_options.normlowchecked && @processing_options.normcontchecked\n            @input_section.doc.normalize(@processing_options.normcontchecked, @input_section.lang,\n                                         @processing_options.normlowchecked)\n            update_progress(3)\n          elsif !@processing_options.normchecked && @processing_options.normlowchecked && @processing_options.normcontchecked\n            @processing_options.norm.checked = true\n            @input_section.doc.normalize(@processing_options.normcontchecked, @input_section.lang,\n                                         @processing_options.normlowchecked)\n            @processing_options.count += 1\n            update_progress(3)\n          elsif (!@processing_options.normchecked && @processing_options.normlowchecked && !@processing_options.normcontchecked) ||\n                (!@processing_options.normchecked && !@processing_options.normlowchecked && @processing_options.normcontchecked)\n            @processing_options.norm.checked = true\n            @input_section.doc.normalize(@processing_options.normcontchecked, @input_section.lang,\n                                         @processing_options.normlowchecked)\n            @processing_options.count += 1\n            update_progress(2)\n          end\n        end\n\n        def process_nlp\n          process_tokenization\n          process_stopwords\n          process_lemmatization\n          process_pos_tagging\n          process_ner\n        end\n\n        def get_input_output_paths\n          input_path = @input_section.input.to_s\n          relative_path = input_path.to_s.sub(%r{^/}, '')\n          output_path = File.join('output', @input_section.projectname, relative_path)\n          [input_path, output_path]\n        end\n\n        def process_tokenization\n          return unless @processing_options.tokchecked\n\n          tokenizer = Pipeline::Tokenizer.new\n          input_path, output_path = get_input_output_paths\n\n          FileUtils.mkdir_p(File.dirname(output_path))\n          tokenizer.tokenize(File.read(input_path))\n          update_progress\n        end\n\n        def process_stopwords\n          return unless @processing_options.srchecked\n\n          if !@processing_options.tokchecked && !@processing_options.autotokchecked\n            tokenizer = Pipeline::Tokenizer.new\n            input_path, output_path = get_input_output_paths\n\n            FileUtils.mkdir_p(File.dirname(output_path))\n            tokenizer.tokenize(File.read(input_path))\n            @processing_options.count += 1\n            update_progress\n          end\n\n          @input_section.doc.stopwordsclean(@input_section.lang)\n          update_progress\n        end\n\n        def process_lemmatization\n          return unless @processing_options.lemchecked\n\n          if !@processing_options.tokchecked && !@processing_options.autotokchecked\n            tokenizer = Pipeline::Tokenizer.new\n            input_path, output_path = get_input_output_paths\n\n            FileUtils.mkdir_p(File.dirname(output_path))\n            tokenizer.tokenize(File.read(input_path))\n            @processing_options.count += 1\n            update_progress\n          end\n\n          @input_section.doc.lemmatizer(@input_section.lang)\n          update_progress\n        end\n\n        def process_pos_tagging\n          return unless @processing_options.poschecked\n\n          if !@processing_options.tokchecked && !@processing_options.autotokchecked\n            tokenizer = Pipeline::Tokenizer.new\n            input_path, output_path = get_input_output_paths\n\n            FileUtils.mkdir_p(File.dirname(output_path))\n            tokenizer.tokenize(File.read(input_path))\n            @processing_options.count += 1\n            update_progress\n          end\n\n          @input_section.doc.tagger(@input_section.lang)\n          update_progress\n        end\n\n        def process_ner\n          return unless @processing_options.nerchecked\n\n          if !@processing_options.tokchecked && !@processing_options.autotokchecked\n            tokenizer = Pipeline::Tokenizer.new\n            input_path, output_path = get_input_output_paths\n\n            FileUtils.mkdir_p(File.dirname(output_path))\n            tokenizer.tokenize(File.read(input_path))\n            @processing_options.count += 1\n            update_progress\n          end\n\n          @input_section.doc.ner(@input_section.lang)\n          update_progress\n        end\n\n        def update_progress(increment = 1)\n          @fincount += increment\n          progress = (@fincount * 100.0 / @processing_options.count).round\n          progress = [progress, 100].min # Ensure progress never exceeds 100\n          @progressbar.value = progress\n          @label.text = 'Text processing finished!' if progress == 100\n        end\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "features.rb",
      "path": "/crumbler/pipeline/",
      "content": "#!/usr/bin/env ruby\nrequire_relative 'tasks/cleaner'\nrequire_relative 'tasks/lemmatizer'\nrequire_relative 'tasks/ner'\nrequire_relative 'tasks/tagger'\nrequire_relative 'tasks/tokenizer'\n\nmodule Crumbler\n  module Pipeline\n    class Features\n      class Error < StandardError; end\n      class FileNotFoundError < Error; end\n      class ProcessingError < Error; end\n      class ValidationError < Error; end\n\n      include Logging\n\n      attr_reader :cleaner, :tokenizer, :tagger, :lemmatizer, :ner, :processing_stats\n\n      def initialize\n        @cleaner = Crumbler::Pipeline::Cleaner.new\n        @tokenizer = Crumbler::Pipeline::Tokenizer.new\n        @tagger = Crumbler::Pipeline::Tagger.new\n        @lemmatizer = Crumbler::Pipeline::Lemmatizer.new\n        @ner = Crumbler::Pipeline::Ner.new\n        @processing_stats = { processed: 0, failed: 0, warnings: 0 }\n      end\n\n      def newproject(input, projectname)\n        validate_input!(input)\n        setup_project_directory(projectname)\n        process_input(input)\n      rescue Error => e\n        logger.error(\"Project creation failed: #{e.message}\")\n        raise\n      rescue StandardError => e\n        logger.error(\"Unexpected error in project creation: #{e.message}\")\n        raise Error, \"Failed to create project: #{e.message}\"\n      end\n\n      private\n\n      def validate_input!(input)\n        raise ValidationError, 'Input cannot be empty' if !input || input.strip.empty?\n\n        if File.file?(input)\n          validate_file!(input)\n        elsif File.directory?(input)\n          validate_directory!(input)\n        elsif input.match?(URI::DEFAULT_PARSER.make_regexp)\n          validate_url!(input)\n        else\n          raise ValidationError, \"Invalid input: #{input}\"\n        end\n      end\n\n      def validate_file!(file_path)\n        raise FileNotFoundError, \"File not found: #{file_path}\" unless File.exist?(file_path)\n\n        unless Config::SUPPORTED_EXTENSIONS.include?(File.extname(file_path).downcase)\n          raise ValidationError, \"Unsupported file type: #{File.extname(file_path)}\"\n        end\n\n        if File.size(file_path) > Config::MAX_FILE_SIZE\n          raise ValidationError, \"File too large: #{File.size(file_path)} bytes (max: #{Config::MAX_FILE_SIZE})\"\n        end\n\n        return unless File.zero?(file_path)\n\n        raise ValidationError, \"File is empty: #{file_path}\"\n      end\n\n      def validate_directory!(dir)\n        raise FileNotFoundError, \"Directory not found: #{dir}\" unless Dir.exist?(dir)\n\n        filetypes = 'pdf,md,markdown,txt,json,jsonl,html,png,wav,mp3'\n        files = Dir.glob(File.join(dir, \"**{,/*/**}/*.{#{filetypes}}\"))\n                   .select { |f| File.file?(f) }\n\n        raise ValidationError, \"No files found in directory: #{dir}\" if files.empty?\n\n        invalid_files = files.reject { |f| validate_input_file(f) }\n        return if invalid_files.empty?\n\n        logger.warn(\"Invalid files found: #{invalid_files.join(', ')}\")\n        @processing_stats[:warnings] += invalid_files.size\n      end\n\n      def validate_url!(url)\n        uri = URI.parse(url)\n        raise ValidationError, \"Invalid URL: #{url}\" unless uri.is_a?(URI::HTTP) || uri.is_a?(URI::HTTPS)\n      rescue URI::InvalidURIError\n        raise ValidationError, \"Invalid URL format: #{url}\"\n      end\n\n      def setup_project_directory(projectname)\n        @projectname = projectname\n        @projectdir = File.join('output', projectname)\n        ensure_directory(@projectdir)\n      end\n\n      # Helper method to ensure directory exists\n      def ensure_directory(dir)\n        FileUtils.mkdir_p(dir) unless Dir.exist?(dir)\n        dir\n      end\n\n      # Helper method to validate file\n      def validate_input_file(file_path)\n        return false unless file_path && File.exist?(file_path)\n        return false unless Config::SUPPORTED_EXTENSIONS.include?(File.extname(file_path).downcase)\n        return false if File.size(file_path) > Config::MAX_FILE_SIZE\n\n        true\n      end\n\n      def process_input(input)\n        if File.file?(input)\n          process_single_file(input)\n        elsif File.directory?(input)\n          process_directory(input)\n        else\n          process_url(input)\n        end\n      end\n\n      def process_single_file(file_path)\n        copy_and_process_file(file_path)\n      rescue StandardError => e\n        handle_processing_error(file_path, e)\n      end\n\n      def process_directory(dir_path)\n        filetypes = 'pdf,md,markdown,txt,json,jsonl,html,png,wav,mp3'\n        Dir.glob(File.join(dir_path, \"**{,/*/**}/*.{#{filetypes}}\")).each do |file|\n          next unless File.file?(file)\n\n          begin\n            copy_and_process_file(file) if validate_input_file(file)\n          rescue StandardError => e\n            handle_processing_error(file, e)\n          end\n        end\n      end\n\n      def process_url(url)\n        content = fetch_url_content(url)\n        url_path = url.gsub(%r{^https?://}, '').gsub(%r{[^a-zA-Z0-9/.]}, '_')\n        output_path = File.join(@projectdir, url_path)\n        ensure_directory(File.dirname(output_path))\n        File.write(output_path, content)\n        @processing_stats[:processed] += 1\n      rescue StandardError => e\n        handle_processing_error(url, e)\n      end\n\n      def fetch_url_content(url)\n        response = URI.open(url)\n        doc = Nokogiri::HTML(response)\n        doc.search('p', 'text').map(&:text).join('\\n')\n      rescue OpenURI::HTTPError => e\n        raise ProcessingError, \"Failed to fetch URL (#{e.message}): #{url}\"\n      rescue StandardError => e\n        raise ProcessingError, \"Error processing URL: #{e.message}\"\n      end\n\n      def copy_and_process_file(file_path)\n        relative_path = file_path.start_with?('/') ? file_path[1..-1] : file_path\n        output_path = File.join(@projectdir, relative_path)\n        ensure_directory(File.dirname(output_path))\n\n        FileUtils.cp(file_path, output_path)\n        process_content(file_path, output_path)\n        @processing_stats[:processed] += 1\n      end\n\n      def process_content(file_path, output_path)\n        content = File.read(file_path)\n        doc = Nokogiri::HTML(content)\n        processed_content = doc.search('p').map(&:text).join('\\n')\n\n        # Handle encoding for special characters\n        processed_content = processed_content.encode('utf-8', invalid: :replace, undef: :replace)\n\n        File.write(output_path, processed_content)\n      rescue Encoding::InvalidByteSequenceError => e\n        raise ProcessingError, \"Encoding error in file #{file_path}: #{e.message}\"\n      rescue StandardError => e\n        raise ProcessingError, \"Failed to process content: #{e.message}\"\n      end\n\n      def handle_processing_error(source, error)\n        logger.error(\"Error processing #{source}: #{error.message}\")\n        @processing_stats[:failed] += 1\n        raise ProcessingError, \"Failed to process #{source}: #{error.message}\"\n      end\n\n      def cleantext\n        validate_project_state!\n\n        Dir.glob(File.join(@projectdir, '**', '*')).each do |file_path|\n          next unless File.file?(file_path)\n\n          begin\n            process_file_cleaning(file_path)\n          rescue StandardError => e\n            handle_processing_error(file_path, e)\n          end\n        end\n\n        log_processing_summary\n      end\n\n      def process_file_cleaning(file_path)\n        relative_path = file_path[@projectdir.length + 1..-1]\n        @filename = File.basename(relative_path, '.*')\n\n        @text2process = File.read(file_path)\n        @text2process = @cleaner.process(@text2process)\n\n        output_path = File.join(File.dirname(file_path), \"#{@filename}_cl.txt\")\n        ensure_directory(File.dirname(output_path))\n        File.write(output_path, @text2process)\n\n        logger.info(\"Successfully cleaned file: #{relative_path}\")\n        @processing_stats[:processed] += 1\n      end\n\n      def validate_project_state!\n        raise Error, 'Project directory not set' unless @projectdir\n        raise Error, \"Project directory not found: #{@projectdir}\" unless Dir.exist?(@projectdir)\n      end\n\n      def log_processing_summary\n        logger.info('Processing completed:')\n        logger.info(\"  Processed: #{@processing_stats[:processed]}\")\n        logger.info(\"  Failed: #{@processing_stats[:failed]}\")\n        logger.info(\"  Warnings: #{@processing_stats[:warnings]}\")\n      end\n\n      def normalize(contractions = false, language = 'EN', lowercase = false)\n        validate_project_state!\n        validate_language!(language)\n\n        files = get_files_to_process\n\n        files.each do |file|\n          process_file_normalization(file, contractions, language, lowercase)\n        rescue StandardError => e\n          handle_processing_error(file, e)\n        end\n\n        log_processing_summary\n      end\n\n      def get_files_to_process\n        Dir.glob(File.join(@projectdir, '**', '*'))\n           .select { |f| File.file?(f) }\n           .sort_by { |f| File.mtime(f) }\n           .take(@filenumber || 1)\n      end\n\n      def validate_language!(language)\n        return if Config::SUPPORTED_LANGUAGES.key?(language.upcase)\n\n        raise ValidationError, \"Unsupported language: #{language}\"\n      end\n\n      def process_file_normalization(file_path, contractions, language, lowercase)\n        return unless File.exist?(file_path)\n\n        relative_path = file_path[@projectdir.length + 1..-1]\n        @filename = File.basename(relative_path, '.*')\n        @text2process = File.read(file_path)\n\n        @text2process = @cleaner.normalize(@text2process,\n                                           contractions: contractions,\n                                           language: language,\n                                           lowercase: lowercase)\n\n        suffix = lowercase ? '_nl' : '_n'\n        output_path = File.join(File.dirname(file_path), \"#{@filename}#{suffix}.txt\")\n        ensure_directory(File.dirname(output_path))\n        File.write(output_path, @text2process)\n\n        logger.info(\"Successfully normalized file: #{relative_path}\")\n        @processing_stats[:processed] += 1\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "cleaner.rb",
      "path": "/crumbler/pipeline/tasks/",
      "content": "#!/usr/bin/env ruby\n\nmodule Crumbler\n  module Pipeline\n    class Cleaner\n      def initialize\n        # No initialization needed for now\n      end\n\n      # Clean raw text from code, markup, special symbols, urls, digits and additional spaces\n      def clean(text)\n        text.gsub('\\n', '')\n            .gsub('\\r', '')\n            .gsub(/\\\\u[a-f0-9]{4}/i, '')\n            .gsub(%r{https?://(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?://(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}}, '')\n            .gsub(/\\d/, '')\n            .gsub(/[^\\w\\s.'Â´`Ã¤Ã„Ã¶Ã–Ã¼ÃœÃŸ]/, '')\n            .gsub(/\\.{2,}/, ' ')\n            .gsub(/ {2,}/, ' ')\n      end\n\n      # Normalize text with optional contractions handling and lowercasing\n      def normalize(text, contractions: false, language: 'EN', lowercase: false)\n        text = text.gsub('.', '')\n                   .gsub(',', '')\n                   .gsub('!', '')\n                   .gsub('?', '')\n                   .gsub(':', '')\n                   .gsub(';', '')\n                   .gsub('(', '')\n                   .gsub(')', '')\n                   .gsub('[', '')\n                   .gsub(']', '')\n                   .gsub('\"', '')\n                   .gsub('â€ž', '')\n                   .gsub('Â»', '')\n                   .gsub('Â«', '')\n                   .gsub('â€º', '')\n                   .gsub('â€¹', '')\n                   .gsub('â€“', '')\n\n        # Handle contractions based on language if enabled\n        if contractions\n          text = if language == 'EN'\n                   text.gsub(/n't\\b/, ' not')\n                       .gsub(/'re\\b/, ' are')\n                       .gsub(/'m\\b/, ' am')\n                       .gsub(/'ll\\b/, ' will')\n                       .gsub(/'ve\\b/, ' have')\n                       .gsub(/'d\\b/, ' would')\n                       .gsub(/'s\\b/, ' is')\n                 else # DE\n                   text.gsub(/(\\w)'(\\w)/, '\\1\\2') # Remove apostrophes between letters\n                 end\n        end\n\n        lowercase ? text.downcase : text\n      end\n\n      # Convenience method to both clean and normalize text\n      def process(text, contractions: false, language: 'EN', lowercase: false)\n        normalized = normalize(clean(text), contractions: contractions, language: language, lowercase: lowercase)\n        normalized.strip\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "lemmatizer.rb",
      "path": "/crumbler/pipeline/tasks/",
      "content": "#!/usr/bin/env ruby\nrequire 'ruby-spacy'\n\nmodule Crumbler\n  module Pipeline\n    class Lemmatizer\n      def initialize\n        @en = Spacy::Language.new('en_core_web_lg')\n        @de = Spacy::Language.new('de_core_news_lg')\n      end\n\n      # Lemmatize text and return array of token-lemma pairs\n      def lemmatize(text, language: 'EN')\n        doc = language == 'EN' ? @en.read(text) : @de.read(text)\n\n        doc.map do |token|\n          {\n            text: token.text,\n            lemma: token.lemma\n          }\n        end\n      end\n\n      # Export lemmatized tokens to different formats\n      def export(lemmatized_tokens, format: :hash)\n        case format\n        when :hash\n          lemmatized_tokens\n        when :text\n          lemmatized_tokens.map { |t| \"#{t[:text]}: lemma:#{t[:lemma]}\" }\n        when :table\n          [%w[text lemma]] + lemmatized_tokens.map { |t| [t[:text], t[:lemma]] }\n        else\n          raise ArgumentError, \"Unsupported format: #{format}\"\n        end\n      end\n\n      # Process text by lemmatizing and exporting in specified format\n      def process(text, language: 'EN', format: :hash)\n        lemmatized = lemmatize(text, language: language)\n        export(lemmatized, format: format)\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "ner.rb",
      "path": "/crumbler/pipeline/tasks/",
      "content": "#!/usr/bin/env ruby\nrequire 'ruby-spacy'\n\nmodule Crumbler\n  module Pipeline\n    class Ner\n      def initialize\n        @en = Spacy::Language.new('en_core_web_lg')\n        @de = Spacy::Language.new('de_core_news_lg')\n      end\n\n      # Extract named entities from text\n      def extract_entities(text, language: 'EN')\n        doc = language == 'EN' ? @en.read(text) : @de.read(text)\n\n        doc.ents.map do |entity|\n          {\n            text: entity.text,\n            label: entity.label\n          }\n        end\n      end\n\n      # Export entities to different formats\n      def export(entities, format: :hash)\n        case format\n        when :hash\n          entities\n        when :csv\n          [%w[text label]] + entities.map { |e| [e[:text], e[:label]] }\n        when :xml\n          builder = Nokogiri::XML::Builder.new do |xml|\n            xml.root do\n              entities.each do |entity|\n                xml.tokens('token' => entity[:text]) do\n                  xml.label entity[:label]\n                end\n              end\n            end\n          end\n          builder.to_xml\n        else\n          raise ArgumentError, \"Unsupported format: #{format}\"\n        end\n      end\n\n      # Process text by extracting entities and exporting in specified format\n      def process(text, language: 'EN', format: :hash)\n        entities = extract_entities(text, language: language)\n        export(entities, format: format)\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "tagger.rb",
      "path": "/crumbler/pipeline/tasks/",
      "content": "#!/usr/bin/env ruby\nrequire 'ruby-spacy'\n\nmodule Crumbler\n  module Pipeline\n    class Tagger\n      def initialize\n        @en = Spacy::Language.new('en_core_web_lg')\n        @de = Spacy::Language.new('de_core_news_lg')\n      end\n\n      # Tag tokens with part-of-speech information\n      def tag(text, language: 'EN')\n        doc = language == 'EN' ? @en.read(text) : @de.read(text)\n\n        doc.map do |token|\n          {\n            text: token.text,\n            pos: token.pos,\n            tag: token.tag\n          }\n        end\n      end\n\n      # Export tagged tokens to different formats\n      def export(tagged_tokens, format: :hash)\n        case format\n        when :hash\n          tagged_tokens\n        when :csv\n          [%w[text pos tag]] + tagged_tokens.map { |t| [t[:text], t[:pos], t[:tag]] }\n        when :xml\n          builder = Nokogiri::XML::Builder.new do |xml|\n            xml.root do\n              tagged_tokens.each do |token|\n                xml.tokens('token' => token[:text]) do\n                  xml.pos token[:pos]\n                  xml.tag token[:tag]\n                end\n              end\n            end\n          end\n          builder.to_xml\n        else\n          raise ArgumentError, \"Unsupported format: #{format}\"\n        end\n      end\n\n      # Process text by tagging and exporting in specified format\n      def process(text, language: 'EN', format: :hash)\n        tagged = tag(text, language: language)\n        export(tagged, format: format)\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "tokenizer.rb",
      "path": "/crumbler/pipeline/tasks/",
      "content": "#!/usr/bin/env ruby\n\nrequire 'pragmatic_tokenizer'\n\nmodule Crumbler\n  module Pipeline\n    class Tokenizer\n      def initialize\n        @tokenizer_options = {\n          expand_contractions: true,\n          remove_stop_words: false,\n          downcase: false,\n          punctuation: :none,\n          numbers: :none,\n          clean: true\n        }\n      end\n\n      # Tokenize input text and return array of tokens\n      def tokenize(text, language: 'EN')\n        lang = language == 'EN' ? :en : :de\n        tokenizer = PragmaticTokenizer::Tokenizer.new(\n          @tokenizer_options.merge(language: lang)\n        )\n        tokenizer.tokenize(text)\n      end\n\n      # Remove stopwords from tokenized text\n      def remove_stopwords(tokens, language: 'EN')\n        lang = language == 'EN' ? :en : :de\n        tokenizer = PragmaticTokenizer::Tokenizer.new(\n          @tokenizer_options.merge(\n            language: lang,\n            remove_stop_words: true\n          )\n        )\n        # We need to rejoin tokens and retokenize to use PragmaticTokenizer's\n        # built-in stopword removal\n        tokenizer.tokenize(tokens.join(' '))\n      end\n\n      # Process text by tokenizing and optionally removing stopwords\n      def process(text, language: 'EN', remove_stopwords: false)\n        tokens = tokenize(text, language: language)\n        remove_stopwords ? remove_stopwords(tokens, language: language) : tokens\n      end\n    end\n  end\nend\n"
    },
    {
      "filename": "logging.rb",
      "path": "/utils/",
      "content": "#!/usr/bin/env ruby\n# frozen_string_literal: true\n\nmodule Logging\n  module_function\n\n  require 'logger'\n  require 'fileutils'\n\n  # The directory where log files will be stored.\n  LOG_DIR = File.expand_path(File.join(__dir__, '../..', 'log'))\n\n  # The default log level.\n  LOG_LEVEL = Logger::INFO\n\n  # The maximum size of a log file in bytes (2MB).\n  LOG_MAX_SIZE = 2_145_728\n\n  # The maximum number of log files to keep.\n  LOG_MAX_FILES = 100\n\n  # A hash to store loggers for different classes and methods.\n  @loggers = {}\n\n  # Ensure log directory exists\n  FileUtils.mkdir_p(LOG_DIR) unless Dir.exist?(LOG_DIR)\n\n  # Returns the logger for the current class and method.\n  #\n  # @return [Logger] The logger object.\n  def logger\n    # Get the name of the current class.\n    classname = self.class.name\n\n    # Get the name of the current method.\n    methodname = caller(1..1).first[/`([^']*)'/, 1]\n\n    # Get the logger for the current class, or create a new one if it doesn't exist.\n    @logger ||= Logging.logger_for(classname, methodname)\n\n    # Set the progname of the logger to include the class and method name.\n    @logger.progname = \"#{classname}##{methodname}\"\n\n    # Return the logger object.\n    @logger\n  end\n\n  class << self\n    # Returns the default log level, considering environment.\n    #\n    # @return [Integer] The log level.\n    def log_level\n      case ENV['RUBY_ENV']\n      when 'production'\n        Logger::INFO\n      when 'test'\n        Logger::ERROR\n      else\n        Logger::DEBUG\n      end\n    end\n\n    # Returns the logger for the specified class and method.\n    #\n    # @param classname [String] The name of the class.\n    # @param methodname [String] The name of the method.\n    #\n    # @return [Logger] The logger object.\n    def logger_for(classname, methodname)\n      # Get the logger for the specified class, or create a new one if it doesn't exist.\n      @loggers[classname] ||= configure_logger_for(classname, methodname)\n    end\n\n    # Configures a logger for the specified class and method.\n    #\n    # @param classname [String] The name of the class.\n    # @param methodname [String] The name of the method.\n    #\n    # @return [Logger] The configured logger object.\n    def configure_logger_for(classname, methodname)\n      # Get the current date in YYYY-MM-DD format.\n      current_date = Time.now.strftime('%Y-%m-%d')\n\n      # Construct the log file path.\n      log_file = File.join(LOG_DIR, \"crumbler-#{current_date}.log\")\n\n      # Create a new logger object with daily rotation.\n      logger = Logger.new(log_file, LOG_MAX_FILES, LOG_MAX_SIZE)\n\n      # Set the log level based on environment.\n      logger.level = log_level\n\n      # Configure the log format.\n      logger.formatter = proc do |severity, datetime, progname, msg|\n        \"[#{datetime}] #{severity} -- #{classname}##{methodname}: #{msg}\\n\"\n      end\n\n      # Return the configured logger object.\n      logger\n    end\n\n    # Clear all loggers (useful for testing).\n    #\n    # @return [void]\n    def clear_loggers!\n      @loggers = {}\n    end\n  end\nend\n"
    }
  ]
}
